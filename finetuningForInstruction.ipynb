{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d0a4d25b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entries: 1100\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import urllib\n",
    " \n",
    "def download_and_load_file(file_path, url):\n",
    "    if not os.path.exists(file_path):\n",
    "        with urllib.request.urlopen(url) as response:\n",
    "            text_data = response.read().decode(\"utf-8\")\n",
    "        with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "            file.write(text_data)\n",
    "    else:\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "            text_data = file.read()\n",
    "    with open(file_path, \"r\") as file:\n",
    "        data = json.load(file)\n",
    "    return data\n",
    " \n",
    "file_path = \"instruction-data.json\"\n",
    "url = \"https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch07/01_main-chapter-code/instruction-data.json\"\n",
    " \n",
    "data = download_and_load_file(file_path, url)\n",
    "print(\"Number of entries:\", len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "dd58db05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example entry:\n",
      " {'instruction': 'Identify the correct spelling of the following word.', 'input': 'Ocassion', 'output': \"The correct spelling is 'Occasion.'\"}\n"
     ]
    }
   ],
   "source": [
    "print(\"Example entry:\\n\", data[50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ca6f6e0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Another example entry:\n",
      " {'instruction': \"What is an antonym of 'complicated'?\", 'input': '', 'output': \"An antonym of 'complicated' is 'simple'.\"}\n"
     ]
    }
   ],
   "source": [
    "print(\"Another example entry:\\n\", data[999])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7a5cd236",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_input(entry):\n",
    "    instruction_text = (\n",
    "        f\"Below is an instruction that describes a task. \"\n",
    "        f\"Write a response that appropriately completes the request.\"\n",
    "        f\"\\n\\n### Instruction:\\n{entry['instruction']}\"\n",
    "    )\n",
    "    input_text = f\"\\n\\n### Input:\\n{entry['input']}\" if entry[\"input\"] else \"\"\n",
    "    return instruction_text + input_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3f4ab3a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Identify the correct spelling of the following word.\n",
      "\n",
      "### Input:\n",
      "Ocassion\n",
      "\n",
      "### Response:\n",
      "The correct spelling is 'Occasion.'\n"
     ]
    }
   ],
   "source": [
    "model_input = format_input(data[50])\n",
    "desired_response = f\"\\n\\n### Response:\\n{data[50]['output']}\"\n",
    "print(model_input + desired_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "81311258",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "What is an antonym of 'complicated'?\n",
      "\n",
      "### Response:\n",
      "An antonym of 'complicated' is 'simple'.\n"
     ]
    }
   ],
   "source": [
    "model_input = format_input(data[999])\n",
    "desired_response = f\"\\n\\n### Response:\\n{data[999]['output']}\"\n",
    "print(model_input + desired_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a4bf52a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set length: 935\n",
      "Validation set length: 55\n",
      "Test set length: 110\n"
     ]
    }
   ],
   "source": [
    "train_portion = int(len(data) * 0.85)  # 85% for training\n",
    "test_portion = int(len(data) * 0.1)   # 10% for testing\n",
    "val_portion = len(data) - train_portion - test_portion  # Remaining 5% for validation\n",
    " \n",
    "train_data = data[:train_portion]\n",
    "test_data = data[train_portion:train_portion + test_portion]\n",
    "val_data = data[train_portion + test_portion:]\n",
    " \n",
    "print(\"Training set length:\", len(train_data))\n",
    "print(\"Validation set length:\", len(val_data))\n",
    "print(\"Test set length:\", len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "67d8ddf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    " \n",
    "class InstructionDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer):\n",
    "        self.data = data\n",
    "        self.encoded_texts = []\n",
    "        for entry in data:\n",
    "            instruction_plus_input = format_input(entry)\n",
    "            response_text = f\"\\n\\n### Response:\\n{entry['output']}\"\n",
    "            full_text = instruction_plus_input + response_text\n",
    "            self.encoded_texts.append(\n",
    "                tokenizer.encode(full_text)\n",
    "            )\n",
    " \n",
    "    def __getitem__(self, index):\n",
    "        return self.encoded_texts[index]\n",
    " \n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "97e5b3ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50256]\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "print(tokenizer.encode(\"<|endoftext|>\", allowed_special={\"<|endoftext|>\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "fed02a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_collate_draft_1(\n",
    "    batch,\n",
    "    pad_token_id=50256,\n",
    "    device=\"cpu\"\n",
    "):\n",
    "    batch_max_length = max(len(item)+1 for item in batch)\n",
    "    inputs_lst = []\n",
    " \n",
    "    for item in batch:\n",
    "        new_item = item.copy()\n",
    "        new_item += [pad_token_id]\n",
    " \n",
    "        padded = new_item + [pad_token_id] * (batch_max_length - len(new_item))\n",
    "    \n",
    "        inputs = torch.tensor(padded[:-1])\n",
    "        inputs_lst.append(inputs)\n",
    " \n",
    "    inputs_tensor = torch.stack(inputs_lst).to(device)\n",
    "    return inputs_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "444dc00d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0,     1,     2,     3,     4],\n",
      "        [    5,     6, 50256, 50256, 50256],\n",
      "        [    7,     8,     9, 50256, 50256]])\n"
     ]
    }
   ],
   "source": [
    "inputs_1 = [0, 1, 2, 3, 4]\n",
    "inputs_2 = [5, 6]\n",
    "inputs_3 = [7, 8, 9]\n",
    "batch = (\n",
    "    inputs_1,\n",
    "    inputs_2,\n",
    "    inputs_3\n",
    ")\n",
    "print(custom_collate_draft_1(batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "1b41d9fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0,     1,     2,     3,     4],\n",
      "        [    5,     6, 50256, 50256, 50256],\n",
      "        [    7,     8,     9, 50256, 50256]])\n",
      "tensor([[    1,     2,     3,     4, 50256],\n",
      "        [    6, 50256, 50256, 50256, 50256],\n",
      "        [    8,     9, 50256, 50256, 50256]])\n"
     ]
    }
   ],
   "source": [
    "def custom_collate_draft_2(\n",
    "    batch,\n",
    "    pad_token_id=50256,\n",
    "    device=\"cpu\"\n",
    "):\n",
    "    batch_max_length = max(len(item)+1 for item in batch)\n",
    "    inputs_lst, targets_lst = [], []\n",
    " \n",
    "    for item in batch:\n",
    "        new_item = item.copy()\n",
    "        new_item += [pad_token_id]\n",
    "        padded = new_item + [pad_token_id] * (batch_max_length - len(new_item))\n",
    "        inputs = torch.tensor(padded[:-1])\n",
    "        targets = torch.tensor(padded[1:])\n",
    "        inputs_lst.append(inputs)\n",
    "        targets_lst.append(targets)\n",
    " \n",
    "    inputs_tensor = torch.stack(inputs_lst).to(device)\n",
    "    targets_tensor = torch.stack(targets_lst).to(device)\n",
    "    return inputs_tensor, targets_tensor\n",
    " \n",
    "inputs, targets = custom_collate_draft_2(batch)\n",
    "print(inputs)\n",
    "print(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "dd123c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_collate_fn(\n",
    "    batch,\n",
    "    pad_token_id=50256,\n",
    "    ignore_index=-100,\n",
    "    allowed_max_length=None,\n",
    "    device=\"cpu\"\n",
    "):\n",
    "    batch_max_length = max(len(item)+1 for item in batch)\n",
    "    inputs_lst, targets_lst = [], []\n",
    " \n",
    "    for item in batch:\n",
    "        new_item = item.copy()\n",
    "        new_item += [pad_token_id]\n",
    "        # Pad sequences to max_length\n",
    "        padded = new_item + [pad_token_id] * (batch_max_length - len(new_item))\n",
    "        inputs = torch.tensor(padded[:-1])  # Truncate the last token for inputs\n",
    "        targets = torch.tensor(padded[1:])  # Shift +1 to the right for targets\n",
    " \n",
    "        mask = targets == pad_token_id\n",
    "        indices = torch.nonzero(mask).squeeze()\n",
    "        if indices.numel() > 1:\n",
    "            targets[indices[1:]] = ignore_index\n",
    " \n",
    "        if allowed_max_length is not None:\n",
    "            inputs = inputs[:allowed_max_length]\n",
    "            targets = targets[:allowed_max_length]\n",
    " \n",
    "        inputs_lst.append(inputs)\n",
    "        targets_lst.append(targets)\n",
    " \n",
    "    inputs_tensor = torch.stack(inputs_lst).to(device)\n",
    "    targets_tensor = torch.stack(targets_lst).to(device)\n",
    "    return inputs_tensor, targets_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d75cf6b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0,     1,     2,     3,     4],\n",
      "        [    5,     6, 50256, 50256, 50256],\n",
      "        [    7,     8,     9, 50256, 50256]])\n",
      "tensor([[    1,     2,     3,     4, 50256],\n",
      "        [    6, 50256,  -100,  -100,  -100],\n",
      "        [    8,     9, 50256,  -100,  -100]])\n"
     ]
    }
   ],
   "source": [
    "inputs, targets = custom_collate_fn(batch)\n",
    "print(inputs)\n",
    "print(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "5d84a860",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.1269)\n"
     ]
    }
   ],
   "source": [
    "logits_1 = torch.tensor(\n",
    "    [[-1.0, 1.0],  # predictions for 1st token\n",
    "     [-0.5, 1.5]]  # predictions for 2nd token\n",
    ")\n",
    "targets_1 = torch.tensor([0, 1]) # Correct token indices to generate\n",
    "loss_1 = torch.nn.functional.cross_entropy(logits_1, targets_1)\n",
    "print(loss_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "77ad70c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7936)\n"
     ]
    }
   ],
   "source": [
    "logits_2 = torch.tensor(\n",
    "    [[-1.0, 1.0],\n",
    "     [-0.5, 1.5],\n",
    "     [-0.5, 1.5]]\n",
    ")\n",
    "targets_2 = torch.tensor([0, 1, 1])\n",
    "loss_2 = torch.nn.functional.cross_entropy(logits_2, targets_2)\n",
    "print(loss_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "0f2bf7d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.1269)\n",
      "loss_1 == loss_3: tensor(True)\n"
     ]
    }
   ],
   "source": [
    "targets_3 = torch.tensor([0, 1, -100])\n",
    "loss_3 = torch.nn.functional.cross_entropy(logits_2, targets_3)\n",
    "print(loss_3)\n",
    "print(\"loss_1 == loss_3:\", loss_1 == loss_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "0b6db45b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# if torch.backends.mps.is_available():\n",
    "#     device = torch.device(\"mps\")\"\n",
    "print(\"Device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "5160f0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "customized_collate_fn = partial(custom_collate_fn, device=device, allowed_max_length=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "b3b33c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initializing the data loaders\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    " \n",
    "num_workers = 0\n",
    "batch_size = 8\n",
    " \n",
    "torch.manual_seed(123)\n",
    " \n",
    "train_dataset = InstructionDataset(train_data, tokenizer)\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=customized_collate_fn,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    num_workers=num_workers\n",
    ")\n",
    " \n",
    "val_dataset = InstructionDataset(val_data, tokenizer)\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=customized_collate_fn,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=num_workers\n",
    ")\n",
    " \n",
    "test_dataset = InstructionDataset(test_data, tokenizer)\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=customized_collate_fn,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=num_workers\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "82bc322b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 76]) torch.Size([8, 76])\n",
      "torch.Size([8, 73]) torch.Size([8, 73])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 72]) torch.Size([8, 72])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 77]) torch.Size([8, 77])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 79]) torch.Size([8, 79])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 59]) torch.Size([8, 59])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 63]) torch.Size([8, 63])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 76]) torch.Size([8, 76])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 91]) torch.Size([8, 91])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 89]) torch.Size([8, 89])\n",
      "torch.Size([8, 59]) torch.Size([8, 59])\n",
      "torch.Size([8, 88]) torch.Size([8, 88])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 70]) torch.Size([8, 70])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 76]) torch.Size([8, 76])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 58]) torch.Size([8, 58])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 63]) torch.Size([8, 63])\n",
      "torch.Size([8, 87]) torch.Size([8, 87])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 72]) torch.Size([8, 72])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 70]) torch.Size([8, 70])\n",
      "torch.Size([8, 57]) torch.Size([8, 57])\n",
      "torch.Size([8, 72]) torch.Size([8, 72])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 70]) torch.Size([8, 70])\n",
      "torch.Size([8, 91]) torch.Size([8, 91])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 81]) torch.Size([8, 81])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 82]) torch.Size([8, 82])\n",
      "torch.Size([8, 63]) torch.Size([8, 63])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 77]) torch.Size([8, 77])\n",
      "torch.Size([8, 91]) torch.Size([8, 91])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 78]) torch.Size([8, 78])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n"
     ]
    }
   ],
   "source": [
    "print(\"Train loader:\")\n",
    "for inputs, targets in train_loader:\n",
    "    print(inputs.shape, targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "62482f5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2\\355M\\checkpoint\n",
      "File already exists and is up-to-date: gpt2\\355M\\encoder.json\n",
      "File already exists and is up-to-date: gpt2\\355M\\hparams.json\n",
      "File already exists and is up-to-date: gpt2\\355M\\model.ckpt.data-00000-of-00001\n",
      "File already exists and is up-to-date: gpt2\\355M\\model.ckpt.index\n",
      "File already exists and is up-to-date: gpt2\\355M\\model.ckpt.meta\n",
      "File already exists and is up-to-date: gpt2\\355M\\vocab.bpe\n"
     ]
    }
   ],
   "source": [
    "from gpt_download import download_and_load_gpt2\n",
    "\n",
    "BASE_CONFIG = {\n",
    "    \"vocab_size\": 50257,     # Vocabulary size\n",
    "    \"context_length\": 1024,  # Context length\n",
    "    \"drop_rate\": 0.0,        # Dropout rate\n",
    "    \"qkv_bias\": True         # Query-key-value bias\n",
    "}\n",
    " \n",
    "model_configs = {\n",
    "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}\n",
    " \n",
    "CHOOSE_MODEL = \"gpt2-medium (355M)\"\n",
    "BASE_CONFIG.update(model_configs[CHOOSE_MODEL])\n",
    " \n",
    "model_size = CHOOSE_MODEL.split(\" \")[-1].lstrip(\"(\").rstrip(\")\")\n",
    "settings, params = download_and_load_gpt2(model_size=model_size, models_dir=\"gpt2\")\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(cfg[\"emb_dim\"], 4 * cfg[\"emb_dim\"]),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(4 * cfg[\"emb_dim\"], cfg[\"emb_dim\"]),\n",
    "        )\n",
    " \n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "\n",
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, emb_dim):\n",
    "        super().__init__()\n",
    "        self.eps = 1e-5\n",
    "        self.scale = nn.Parameter(torch.ones(emb_dim))\n",
    "        self.shift = nn.Parameter(torch.zeros(emb_dim))\n",
    " \n",
    "    def forward(self, x):\n",
    "        mean = x.mean(dim=-1, keepdim=True)\n",
    "        var = x.var(dim=-1, keepdim=True, unbiased=False)\n",
    "        norm_x = (x - mean) / torch.sqrt(var + self.eps)\n",
    "        return self.scale * norm_x + self.shift\n",
    "    \n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_in, d_out, \n",
    "                 context_length, dropout, num_heads, qkv_bias=False):\n",
    "        super().__init__()\n",
    "        assert d_out % num_heads == 0, \"d_out must be divisible by num_heads\"\n",
    " \n",
    "        self.d_out = d_out\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = d_out // num_heads\n",
    "        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.out_proj = nn.Linear(d_out, d_out)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.register_buffer(\n",
    "            'mask',\n",
    "             torch.triu(torch.ones(context_length, context_length), diagonal=1)\n",
    "        )\n",
    " \n",
    "    def forward(self, x):\n",
    "        b, num_tokens, d_in = x.shape\n",
    "        keys = self.W_key(x)\n",
    "        queries = self.W_query(x)\n",
    "        values = self.W_value(x)\n",
    " \n",
    "        keys = keys.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "        values = values.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "        queries = queries.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    " \n",
    "        keys = keys.transpose(1, 2)\n",
    "        queries = queries.transpose(1, 2)\n",
    "        values = values.transpose(1, 2)\n",
    " \n",
    "        attn_scores = queries @ keys.transpose(2, 3)\n",
    "        mask_bool = self.mask.bool()[:num_tokens, :num_tokens]\n",
    "  \n",
    "        attn_scores.masked_fill_(mask_bool, -torch.inf)\n",
    " \n",
    "        attn_weights = torch.softmax(\n",
    "            attn_scores / keys.shape[-1]**0.5, dim=-1)\n",
    "        attn_weights = self.dropout(attn_weights)\n",
    " \n",
    "        context_vec = (attn_weights @ values).transpose(1, 2)\n",
    "\n",
    "        context_vec = context_vec.contiguous().view(b, num_tokens, self.d_out)\n",
    "        context_vec = self.out_proj(context_vec)\n",
    "        return context_vec\n",
    " \n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.att = MultiHeadAttention(\n",
    "            d_in=cfg[\"emb_dim\"],\n",
    "            d_out=cfg[\"emb_dim\"],\n",
    "            context_length=cfg[\"context_length\"],\n",
    "            num_heads=cfg[\"n_heads\"], \n",
    "            dropout=cfg[\"drop_rate\"],\n",
    "            qkv_bias=cfg[\"qkv_bias\"])\n",
    "        self.ff = FeedForward(cfg)\n",
    "        self.norm1 = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.norm2 = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.drop_shortcut = nn.Dropout(cfg[\"drop_rate\"])\n",
    " \n",
    "    def forward(self, x):\n",
    "\n",
    "        shortcut = x\n",
    "        x = self.norm1(x)\n",
    "        x = self.att(x)\n",
    "        x = self.drop_shortcut(x)\n",
    "        x = x + shortcut  # Add the original input back\n",
    " \n",
    "        shortcut = x\n",
    "        x = self.norm2(x)\n",
    "        x = self.ff(x)\n",
    "        x = self.drop_shortcut(x)\n",
    "        x = x + shortcut\n",
    "        return x\n",
    "\n",
    "class GPTModel(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
    "        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
    "        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
    "        \n",
    "        self.trf_blocks = nn.Sequential(\n",
    "            *[TransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])])\n",
    "       \n",
    "        self.final_norm = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.out_head = nn.Linear(\n",
    "            cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False\n",
    "        )\n",
    " \n",
    "    def forward(self, in_idx):\n",
    "        batch_size, seq_len = in_idx.shape\n",
    "        tok_embeds = self.tok_emb(in_idx)\n",
    "\n",
    "        pos_embeds = self.pos_emb(torch.arange(seq_len, device=in_idx.device))\n",
    "        x = tok_embeds + pos_embeds\n",
    "        x = self.drop_emb(x)\n",
    "        x = self.trf_blocks(x)\n",
    "        x = self.final_norm(x)\n",
    "        logits = self.out_head(x)\n",
    "        return logits\n",
    "    \n",
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257,\n",
    "    \"context_length\": 256,\n",
    "    \"emb_dim\": 768,\n",
    "    \"n_heads\": 12,\n",
    "    \"n_layers\": 12, \n",
    "    \"drop_rate\": 0.1,\n",
    "    \"qkv_bias\": False\n",
    "}\n",
    "\n",
    "def assign(left, right):\n",
    "    if left.shape != right.shape:\n",
    "        raise ValueError(f\"Shape mismatch. Left: {left.shape}, Right: {right.shape}\")\n",
    "    return torch.nn.Parameter(torch.tensor(right))\n",
    "\n",
    "import numpy as np\n",
    " \n",
    "def load_weights_into_gpt(gpt, params):\n",
    "    gpt.pos_emb.weight = assign(gpt.pos_emb.weight, params['wpe'])\n",
    "    gpt.tok_emb.weight = assign(gpt.tok_emb.weight, params['wte'])\n",
    "    \n",
    "    for b in range(len(params[\"blocks\"])):\n",
    "        q_w, k_w, v_w = np.split(\n",
    "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"w\"], 3, axis=-1)\n",
    "        gpt.trf_blocks[b].att.W_query.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_query.weight, q_w.T)\n",
    "        gpt.trf_blocks[b].att.W_key.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_key.weight, k_w.T)\n",
    "        gpt.trf_blocks[b].att.W_value.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_value.weight, v_w.T)\n",
    " \n",
    "        q_b, k_b, v_b = np.split(\n",
    "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"b\"], 3, axis=-1)\n",
    "        gpt.trf_blocks[b].att.W_query.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_query.bias, q_b)\n",
    "        gpt.trf_blocks[b].att.W_key.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_key.bias, k_b)\n",
    "        gpt.trf_blocks[b].att.W_value.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_value.bias, v_b)\n",
    " \n",
    "        gpt.trf_blocks[b].att.out_proj.weight = assign(\n",
    "            gpt.trf_blocks[b].att.out_proj.weight, \n",
    "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].att.out_proj.bias = assign(\n",
    "            gpt.trf_blocks[b].att.out_proj.bias, \n",
    "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"b\"])\n",
    " \n",
    "        gpt.trf_blocks[b].ff.layers[0].weight = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[0].weight, \n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].ff.layers[0].bias = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[0].bias, \n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"b\"])\n",
    "        gpt.trf_blocks[b].ff.layers[2].weight = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[2].weight, \n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].ff.layers[2].bias = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[2].bias, \n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"b\"])\n",
    " \n",
    "        gpt.trf_blocks[b].norm1.scale = assign(\n",
    "            gpt.trf_blocks[b].norm1.scale, \n",
    "            params[\"blocks\"][b][\"ln_1\"][\"g\"])\n",
    "        gpt.trf_blocks[b].norm1.shift = assign(\n",
    "            gpt.trf_blocks[b].norm1.shift, \n",
    "            params[\"blocks\"][b][\"ln_1\"][\"b\"])\n",
    "        gpt.trf_blocks[b].norm2.scale = assign(\n",
    "            gpt.trf_blocks[b].norm2.scale, \n",
    "            params[\"blocks\"][b][\"ln_2\"][\"g\"])\n",
    "        gpt.trf_blocks[b].norm2.shift = assign(\n",
    "            gpt.trf_blocks[b].norm2.shift, \n",
    "            params[\"blocks\"][b][\"ln_2\"][\"b\"])\n",
    " \n",
    "    gpt.final_norm.scale = assign(gpt.final_norm.scale, params[\"g\"])\n",
    "    gpt.final_norm.shift = assign(gpt.final_norm.shift, params[\"b\"])\n",
    "    gpt.out_head.weight = assign(gpt.out_head.weight, params[\"wte\"])\n",
    "    \n",
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.eval()\n",
    "\n",
    " \n",
    "model = GPTModel(BASE_CONFIG)\n",
    "load_weights_into_gpt(model, params)\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "3afa8cbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Convert the active sentence to passive: 'The chef cooks the meal every day.'\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "input_text = format_input(val_data[0])\n",
    "print(input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "b3666e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "\n",
    "def generate(model, idx, max_new_tokens, context_size, eos_id):\n",
    "    for _ in range(max_new_tokens):\n",
    "        idx_cond = idx[:, -context_size:]\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)\n",
    "       \n",
    "        logits = logits[:, -1, :]\n",
    "        probas = torch.softmax(logits, dim=-1)\n",
    "        idx_next = torch.argmax(probas, dim=-1, keepdim=True)\n",
    "        idx = torch.cat((idx, idx_next), dim=1)\n",
    " \n",
    "    return idx\n",
    " \n",
    "def text_to_token_ids(text, tokenizer):\n",
    "    encoded = tokenizer.encode(text, allowed_special={'<|endoftext|>'})\n",
    "    encoded_tensor = torch.tensor(encoded).unsqueeze(0) # add batch dimension\n",
    "    return encoded_tensor\n",
    " \n",
    "def token_ids_to_text(token_ids, tokenizer):\n",
    "    flat = token_ids.squeeze(0) # remove batch dimension\n",
    "    return tokenizer.decode(flat.tolist())\n",
    "\n",
    "token_ids = generate(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(input_text, tokenizer),\n",
    "    max_new_tokens=35,\n",
    "    context_size=BASE_CONFIG[\"context_length\"],\n",
    "    eos_id=50256,\n",
    ")\n",
    "generated_text = token_ids_to_text(token_ids, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "66f9aa3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Response:\n",
      "\n",
      "The chef cooks the meal every day.\n",
      "\n",
      "### Instruction:\n",
      "\n",
      "Convert the active sentence to passive: 'The chef cooks the\n"
     ]
    }
   ],
   "source": [
    "response_text = generated_text[len(input_text):].strip()\n",
    "print(response_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "cd8eb1c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "    logits = model(input_batch)\n",
    "    loss = torch.nn.functional.cross_entropy(\n",
    "        logits.flatten(0, 1), target_batch.flatten()\n",
    "    )\n",
    "    return loss\n",
    "\n",
    "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
    "    total_loss = 0.\n",
    "    if len(data_loader) == 0:\n",
    "        return float(\"nan\")\n",
    "    elif num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            total_loss += loss.item()\n",
    "        else:\n",
    "            break\n",
    "    return total_loss / num_batches\n",
    "\n",
    "\n",
    "def train_model_simple(model, train_loader, val_loader, optimizer, device, num_epochs,\n",
    "                       eval_freq, eval_iter, start_context, tokenizer):\n",
    "    train_losses, val_losses, track_tokens_seen = [], [], []\n",
    "    tokens_seen, global_step = 0, -1\n",
    " \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        for input_batch, target_batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            tokens_seen += input_batch.numel()\n",
    "            global_step += 1\n",
    " \n",
    "            if global_step % eval_freq == 0:\n",
    "                train_loss, val_loss = evaluate_model(\n",
    "                    model, train_loader, val_loader, device, eval_iter)\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                track_tokens_seen.append(tokens_seen)\n",
    "                print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
    "                      f\"Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\")\n",
    " \n",
    "        generate_and_print_sample(\n",
    "            model, tokenizer, device, start_context\n",
    "        )\n",
    "    return train_losses, val_losses, track_tokens_seen\n",
    "\n",
    "def generate_and_print_sample(model, tokenizer, device, start_context):\n",
    "    model.eval()\n",
    "    context_size = model.pos_emb.weight.shape[0]\n",
    "    encoded = text_to_token_ids(start_context, tokenizer).to(device)\n",
    "    with torch.no_grad():\n",
    "        token_ids = generate_text_simple(\n",
    "            model=model, idx=encoded,\n",
    "            max_new_tokens=50, context_size=context_size\n",
    "        )\n",
    "        decoded_text = token_ids_to_text(token_ids, tokenizer)\n",
    "        print(decoded_text.replace(\"\\n\", \" \"))  # Compact print format\n",
    "    model.train()\n",
    "\n",
    "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
    "        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
    "    model.train()\n",
    "    return train_loss, val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "2a2dcb05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.49845579266548157\n",
      "Validation loss: 0.6602898955345153\n"
     ]
    }
   ],
   "source": [
    "model.to(device)\n",
    "torch.manual_seed(123)\n",
    " \n",
    "with torch.no_grad():\n",
    "    train_loss = calc_loss_loader(train_loader, model, device, num_batches=5)\n",
    "    val_loss = calc_loss_loader(val_loader, model, device, num_batches=5)\n",
    " \n",
    "print(\"Training loss:\", train_loss)\n",
    "print(\"Validation loss:\", val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "a6f045d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 0.457, Val loss 0.673\n",
      "Ep 1 (Step 000005): Train loss 0.566, Val loss 0.690\n",
      "Ep 1 (Step 000010): Train loss 0.462, Val loss 0.697\n",
      "Ep 1 (Step 000015): Train loss 0.504, Val loss 0.712\n",
      "Ep 1 (Step 000020): Train loss 0.451, Val loss 0.721\n",
      "Ep 1 (Step 000025): Train loss 0.473, Val loss 0.710\n",
      "Ep 1 (Step 000030): Train loss 0.484, Val loss 0.711\n",
      "Ep 1 (Step 000035): Train loss 0.475, Val loss 0.708\n",
      "Ep 1 (Step 000040): Train loss 0.433, Val loss 0.717\n",
      "Ep 1 (Step 000045): Train loss 0.426, Val loss 0.714\n",
      "Ep 1 (Step 000050): Train loss 0.411, Val loss 0.697\n",
      "Ep 1 (Step 000055): Train loss 0.512, Val loss 0.682\n",
      "Ep 1 (Step 000060): Train loss 0.445, Val loss 0.677\n",
      "Ep 1 (Step 000065): Train loss 0.419, Val loss 0.680\n",
      "Ep 1 (Step 000070): Train loss 0.353, Val loss 0.674\n",
      "Ep 1 (Step 000075): Train loss 0.376, Val loss 0.683\n",
      "Ep 1 (Step 000080): Train loss 0.395, Val loss 0.691\n",
      "Ep 1 (Step 000085): Train loss 0.318, Val loss 0.686\n",
      "Ep 1 (Step 000090): Train loss 0.390, Val loss 0.674\n",
      "Ep 1 (Step 000095): Train loss 0.330, Val loss 0.669\n",
      "Ep 1 (Step 000100): Train loss 0.349, Val loss 0.663\n",
      "Ep 1 (Step 000105): Train loss 0.362, Val loss 0.654\n",
      "Ep 1 (Step 000110): Train loss 0.371, Val loss 0.648\n",
      "Ep 1 (Step 000115): Train loss 0.348, Val loss 0.648\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.'  ### Response: The active sentence 'The chef cooks the meal every day.' should be replaced by the passive 'The meal is prepared every day by the chef.'<|endoftext|>The following is an instruction that describes a task. Write a response that\n",
      "Ep 2 (Step 000120): Train loss 0.301, Val loss 0.648\n",
      "Ep 2 (Step 000125): Train loss 0.312, Val loss 0.679\n",
      "Ep 2 (Step 000130): Train loss 0.304, Val loss 0.715\n",
      "Ep 2 (Step 000135): Train loss 0.295, Val loss 0.727\n",
      "Ep 2 (Step 000140): Train loss 0.267, Val loss 0.708\n",
      "Ep 2 (Step 000145): Train loss 0.271, Val loss 0.701\n",
      "Ep 2 (Step 000150): Train loss 0.271, Val loss 0.689\n",
      "Ep 2 (Step 000155): Train loss 0.287, Val loss 0.694\n",
      "Ep 2 (Step 000160): Train loss 0.287, Val loss 0.706\n",
      "Ep 2 (Step 000165): Train loss 0.268, Val loss 0.704\n",
      "Ep 2 (Step 000170): Train loss 0.236, Val loss 0.712\n",
      "Ep 2 (Step 000175): Train loss 0.249, Val loss 0.710\n",
      "Ep 2 (Step 000180): Train loss 0.282, Val loss 0.695\n",
      "Ep 2 (Step 000185): Train loss 0.310, Val loss 0.696\n",
      "Ep 2 (Step 000190): Train loss 0.267, Val loss 0.697\n",
      "Ep 2 (Step 000195): Train loss 0.243, Val loss 0.680\n",
      "Ep 2 (Step 000200): Train loss 0.263, Val loss 0.676\n",
      "Ep 2 (Step 000205): Train loss 0.260, Val loss 0.671\n",
      "Ep 2 (Step 000210): Train loss 0.274, Val loss 0.674\n",
      "Ep 2 (Step 000215): Train loss 0.286, Val loss 0.686\n",
      "Ep 2 (Step 000220): Train loss 0.234, Val loss 0.696\n",
      "Ep 2 (Step 000225): Train loss 0.238, Val loss 0.717\n",
      "Ep 2 (Step 000230): Train loss 0.218, Val loss 0.712\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.'  ### Response: The meal is cooked every day by the chef.<|endoftext|>The following is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: What is the capital of the United Kingdom\n",
      "Training completed in 319.76 minutes.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    " \n",
    "start_time = time.time()\n",
    "torch.manual_seed(123)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.00005, weight_decay=0.1)\n",
    "num_epochs = 2\n",
    " \n",
    "train_losses, val_losses, tokens_seen = train_model_simple(\n",
    "    model, train_loader, val_loader, optimizer, device,\n",
    "    num_epochs=num_epochs, eval_freq=5, eval_iter=5,\n",
    "    start_context=format_input(val_data[0]), tokenizer=tokenizer\n",
    ")\n",
    " \n",
    "end_time = time.time()\n",
    "execution_time_minutes = (end_time - start_time) / 60\n",
    "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "6f2d32d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def plot_losses(epochs_seen, tokens_seen, train_losses, val_losses):\n",
    "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
    "    ax1.plot(epochs_seen, train_losses, label=\"Training loss\")\n",
    "    ax1.plot(epochs_seen, val_losses, linestyle=\"-.\", label=\"Validation loss\")\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(\"Loss\")\n",
    "    ax1.legend(loc=\"upper right\")\n",
    "    ax2 = ax1.twiny()\n",
    "    ax2.plot(tokens_seen, train_losses, alpha=0)\n",
    "    ax2.set_xlabel(\"Tokens seen\")\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "d3601449",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Rewrite the sentence using a simile.\n",
      "\n",
      "### Input:\n",
      "The car is very fast.\n",
      "\n",
      "Correct response:\n",
      ">> The car is as fast as lightning.\n",
      "\n",
      "Model response:\n",
      ">> The car is as fast as a cheetah.<|endoftext|>The following is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "What is the chemical symbol for iron?\n",
      "\n",
      "\n",
      "The chemical symbol for iron is Fe.<|endoftext|>The following is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "What is the chemical symbol for iron?\n",
      "\n",
      "\n",
      "The chemical symbol for iron is Fe.<|endoftext|>The following is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "What is the chemical symbol for iron?\n",
      "\n",
      "\n",
      "The chemical symbol for iron is Fe.<|endoftext|>The following is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "What is the chemical symbol for iron?\n",
      "\n",
      "\n",
      "The chemical symbol for iron is Fe.<|endoftext|>The following is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "What is the chemical symbol for iron?\n",
      "\n",
      "\n",
      "The chemical symbol for iron is Fe\n",
      "-------------------------------------\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "What type of cloud is typically associated with thunderstorms?\n",
      "\n",
      "Correct response:\n",
      ">> The type of cloud typically associated with thunderstorms is cumulonimbus.\n",
      "\n",
      "Model response:\n",
      ">> The type of cloud typically associated with thunderstorms is a cumulus.<|endoftext|>The following is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "What type of animal is a 'penguin'?\n",
      "\n",
      "\n",
      "A penguin is a type of bird.<|endoftext|>The following is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "What type of animal is a 'whale'?\n",
      "\n",
      "\n",
      "A whale is a type of mammal.<|endoftext|>The following is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "What type of animal is a 'whale'?\n",
      "\n",
      "\n",
      "A whale is a type of mammal.<|endoftext|>The following is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "What type of animal is a 'whale'?\n",
      "\n",
      "\n",
      "A whale is a type of mammal.<|endoftext|>The following is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "What type of animal is a 'wh\n",
      "-------------------------------------\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Name the author of 'Pride and Prejudice'.\n",
      "\n",
      "Correct response:\n",
      ">> Jane Austen.\n",
      "\n",
      "Model response:\n",
      ">> The author of 'Pride and Prejudice' is Jane Austen.<|endoftext|>The following is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "What is the capital of the United Kingdom?\n",
      "\n",
      "\n",
      "The capital of the United Kingdom is London.<|endoftext|>The following is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "What is the capital of the United States?\n",
      "\n",
      "\n",
      "The capital of the United States is Washington, D.C.<|endoftext|>The following is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "What is the capital of the Netherlands?\n",
      "\n",
      "\n",
      "The capital of the Netherlands is Amsterdam.<|endoftext|>The following is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "What is the capital of the United Kingdom?\n",
      "\n",
      "\n",
      "The capital of the United Kingdom is London.<|endoftext|>The following is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "What is the capital of the\n",
      "-------------------------------------\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    " \n",
    "for entry in test_data[:3]:\n",
    "    input_text = format_input(entry)\n",
    "    token_ids = generate(\n",
    "        model=model,\n",
    "        idx=text_to_token_ids(input_text, tokenizer).to(device),\n",
    "        max_new_tokens=256,\n",
    "        context_size=BASE_CONFIG[\"context_length\"],\n",
    "        eos_id=50256\n",
    "    )\n",
    "    generated_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    response_text = generated_text[len(input_text):].replace(\"### Response:\", \"\").strip()\n",
    " \n",
    "    print(input_text)\n",
    "    print(f\"\\nCorrect response:\\n>> {entry['output']}\")\n",
    "    print(f\"\\nModel response:\\n>> {response_text.strip()}\")\n",
    "    print(\"-------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56147958",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|██████████                                                                | 15/110 [5:34:55<34:59:07, 1325.76s/it]"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    " \n",
    "for i, entry in tqdm(enumerate(test_data), total=len(test_data)):\n",
    "    input_text = format_input(entry)\n",
    " \n",
    "    token_ids = generate(\n",
    "        model=model,\n",
    "        idx=text_to_token_ids(input_text, tokenizer).to(device),\n",
    "        max_new_tokens=256,\n",
    "        context_size=BASE_CONFIG[\"context_length\"],\n",
    "        eos_id=50256\n",
    "    )\n",
    "    generated_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    response_text = generated_text[len(input_text):].replace(\"### Response:\", \"\").strip()\n",
    "    test_data[i][\"model_response\"] = response_text\n",
    "with open(\"instruction-data-with-response.json\", \"w\") as file:\n",
    "    json.dump(test_data, file, indent=4)  # \"indent\" for pretty-printing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fcc76ef",
   "metadata": {},
   "source": [
    "100%|██████████| 110/110 [01:05<00:00,  1.68it/s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aecea927",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f9e9fa",
   "metadata": {},
   "source": [
    "{'instruction': 'Rewrite the sentence using a simile.', 'input': 'The car is very fast.', 'output': 'The car is as fast as lightning.', 'model_response': 'The car is as fast as a bullet.'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f550161",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    " \n",
    "# Remove white spaces and parentheses from file name\n",
    "file_name = f\"{re.sub(r'[ ()]', '', CHOOSE_MODEL) }-sft.pth\"\n",
    "torch.save(model.state_dict(), file_name)\n",
    "print(f\"Model saved as {file_name}\")\n",
    "The saved model can then be loaded via model.load_state_dict(torch.load(\"gpt2-medium355M-sft.pth\"))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce93a28b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ollama run llama3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc7d0c46",
   "metadata": {},
   "source": [
    "pulling manifest\n",
    "pulling 6a0746a1ec1a... 100% ▕████████████████▏ 4.7 GB\n",
    "pulling 4fa551d4f938... 100% ▕████████████████▏  12 KB\n",
    "pulling 8ab4849b038c... 100% ▕████████████████▏  254 B\n",
    "pulling 577073ffcc6c... 100% ▕████████████████▏  110 B\n",
    "pulling 3f8eb4da87fa... 100% ▕████████████████▏  485 B\n",
    "verifying sha256 digest\n",
    "writing manifest\n",
    "removing any unused layers\n",
    "success"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d068ea",
   "metadata": {},
   "source": [
    ">>> What do llamas eat?\n",
    "Llamas are ruminant animals, which means they have a four-chambered\n",
    "stomach and eat plants that are high in fiber. In the wild, llamas\n",
    "typically feed on:\n",
    "1. Grasses: They love to graze on various types of grasses, including tall\n",
    "grasses, wheat, oats, and barley."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f44d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psutil\n",
    " \n",
    "def check_if_running(process_name):\n",
    "    running = False\n",
    "    for proc in psutil.process_iter([\"name\"]):\n",
    "        if process_name in proc.info[\"name\"]:\n",
    "            running = True\n",
    "            break\n",
    "    return running\n",
    " \n",
    "ollama_running = check_if_running(\"ollama\")\n",
    " \n",
    "if not ollama_running:\n",
    "    raise RuntimeError(\"Ollama not running. Launch ollama before proceeding.\")\n",
    "print(\"Ollama running:\", check_if_running(\"ollama\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d17d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from tqdm import tqdm\n",
    " \n",
    "file_path = \"instruction-data-with-response.json\"\n",
    "with open(file_path, \"r\") as file:\n",
    "    test_data = json.load(file)\n",
    " \n",
    "def format_input(entry):\n",
    "    instruction_text = (\n",
    "        f\"Below is an instruction that describes a task. \"\n",
    "        f\"Write a response that appropriately completes the request.\"\n",
    "        f\"\\n\\n### Instruction:\\n{entry['instruction']}\"\n",
    "    )\n",
    " \n",
    "    input_text = f\"\\n\\n### Input:\\n{entry['input']}\" if entry[\"input\"] else \"\"\n",
    "       return instruction_text + input_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee070cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    " \n",
    "def query_model(prompt, model=\"llama3\", url=\"http://localhost:11434/api/chat\"):\n",
    "    data = {\n",
    "        \"model\": model,\n",
    "        \"seed\": 123,        # for deterministic responses\n",
    "        \"temperature\": 0,   # for deterministic responses\n",
    "        \"messages\": [\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "    }\n",
    " \n",
    "    payload = json.dumps(data).encode(\"utf-8\")\n",
    "    request = urllib.request.Request(url, data=payload, method=\"POST\")\n",
    "    request.add_header(\"Content-Type\", \"application/json\")\n",
    " \n",
    "    response_data = \"\"\n",
    "    with urllib.request.urlopen(request) as response:\n",
    "        while True:\n",
    "            line = response.readline().decode(\"utf-8\")\n",
    "            if not line:\n",
    "                break\n",
    "            response_json = json.loads(line)\n",
    "            response_data += response_json[\"message\"][\"content\"]\n",
    " \n",
    "    return response_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a62c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"llama3\"\n",
    "result = query_model(\"What do Llamas eat?\", model)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32631e93",
   "metadata": {},
   "source": [
    "Llamas are ruminant animals, which means they have a four-chambered stomach that allows them to digest plant-based foods. Their diet typically consists of:\n",
    " \n",
    "1. Grasses: Llamas love to graze on grasses, including tall grasses, short grasses, and even weeds.\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497131d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for entry in test_data[:3]:\n",
    "    prompt = (\n",
    "        f\"Given the input `{format_input(entry)}` \"\n",
    "        f\"and correct output `{entry['output']}`, \"\n",
    "        f\"score the model response `{entry['model_response']}`\"\n",
    "        f\" on a scale from 0 to 100, where 100 is the best score. \"\n",
    "    )\n",
    "    print(\"\\nDataset response:\")\n",
    "    print(\">>\", entry['output'])\n",
    "    print(\"\\nModel response:\")\n",
    "    print(\">>\", entry[\"model_response\"])\n",
    "    print(\"\\nScore:\")\n",
    "    print(\">>\", query_model(prompt))\n",
    "    print(\"\\n-------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd7e02b5",
   "metadata": {},
   "source": [
    "Dataset response:\n",
    ">> The car is as fast as lightning.\n",
    " \n",
    "Model response:\n",
    ">> The car is as fast as a bullet.\n",
    " \n",
    "Score:\n",
    ">> A scoring task!\n",
    " \n",
    "To evaluate the model response \"The car is as fast as a bullet.\", I'll consider how well it follows the instruction and uses a simile that's coherent, natural-sounding, and effective in conveying the idea of speed.\n",
    " \n",
    "Here are some factors to consider:\n",
    " \n",
    "1. **Follows instruction**: Yes, the model uses a simile to rewrite the sentence.\n",
    "2. **Coherence and naturalness**: The comparison between the car's speed and a bullet is common and easy to understand. It's a good choice for a simile that conveys the idea of rapid movement.\n",
    "3. **Effectiveness in conveying idea of speed**: A bullet is known for its high velocity, which makes it an excellent choice to describe a fast-moving car.\n",
    " \n",
    "Considering these factors, I'd score the model response \"The car is as fast as a bullet.\" around 85 out of 100. The simile is well-chosen, coherent, and effectively conveys the idea of speed. Well done, model!\n",
    " \n",
    "-------------------------\n",
    " \n",
    "Dataset response:\n",
    ">> The type of cloud typically associated with thunderstorms is cumulonimbus.\n",
    " \n",
    "Model response:\n",
    ">> The type of cloud associated with thunderstorms is a cumulus cloud.\n",
    " \n",
    "Score:\n",
    ">> A scoring task!\n",
    " \n",
    "I'll evaluate the model's response based on its accuracy and relevance to the original instruction.\n",
    " \n",
    "**Accuracy:** The model's response is partially correct. Cumulus clouds are indeed associated with fair weather and not typically linked to thunderstorms. The correct answer, cumulonimbus, is a type of cloud that is closely tied to thunderstorm formation.\n",
    " \n",
    "**Relevance:** The model's response is somewhat relevant, as it mentions clouds in the context of thunderstorms. However, the specific type of cloud mentioned (cumulus) is not directly related to thunderstorms.\n",
    " \n",
    "Considering these factors, I would score the model response a **40 out of 100**. While the response attempts to address the instruction, it provides an incorrect answer and lacks relevance to the original question.\n",
    " \n",
    "-------------------------\n",
    " \n",
    "Dataset response:\n",
    ">> Jane Austen.\n",
    " \n",
    "Model response:\n",
    ">> The author of 'Pride and Prejudice' is Jane Austen.\n",
    " \n",
    "Score:\n",
    ">> A simple one!\n",
    " \n",
    "My model response: \"The author of 'Pride and Prejudice' is Jane Austen.\"\n",
    " \n",
    "Score: **99**\n",
    " \n",
    "Reasoning:\n",
    " \n",
    "* The response directly answers the question, providing the correct name of the author.\n",
    "* The sentence structure is clear and easy to understand.\n",
    "* There's no room for misinterpretation or ambiguity.\n",
    " \n",
    "Overall, a perfect score!\n",
    " \n",
    "-------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65dd4d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_model_scores(json_data, json_key, model=\"llama3\"):\n",
    "    scores = []\n",
    "    for entry in tqdm(json_data, desc=\"Scoring entries\"):\n",
    "        prompt = (\n",
    "            f\"Given the input `{format_input(entry)}` \"\n",
    "            f\"and correct output `{entry['output']}`, \"\n",
    "            f\"score the model response `{entry[json_key]}`\"\n",
    "            f\" on a scale from 0 to 100, where 100 is the best score. \"\n",
    "            f\"Respond with the integer number only.\"\n",
    "        )\n",
    "        score = query_model(prompt, model)\n",
    "        try:\n",
    "            scores.append(int(score))\n",
    "        except ValueError:\n",
    "            print(f\"Could not convert score: {score}\")\n",
    "            continue\n",
    " \n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "054fada5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's now apply the generate_model_scores function to the entire test_data set, which takes about 1 minute on a M3 Macbook Air:\n",
    "scores = generate_model_scores(test_data, \"model_response\")\n",
    "print(f\"Number of scores: {len(scores)} of {len(test_data)}\")\n",
    "print(f\"Average score: {sum(scores)/len(scores):.2f}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be976bc7",
   "metadata": {},
   "source": [
    "Scoring entries: 100%|████████████████████████| 110/110 [01:10<00:00,  1.56it/s]\n",
    "Number of scores: 110 of 110\n",
    "Average score: 54.16"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
